{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for creation of the tabular dataset (env: Scikit-HEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the packges we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pyjet import cluster,DTYPE_PTEPM\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data we want to use to create the images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of load the full large h5 file we are going to make a generator to load the file in batches more menageble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(filename, chunksize=512,total_size=1100000):\n",
    "\n",
    "    m = 0\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        yield pd.read_hdf(filename,start=m*chunksize, stop=(m+1)*chunksize)\n",
    "\n",
    "        m+=1\n",
    "        if (m+1)*chunksize > total_size:\n",
    "            m=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm using the generator to load the events in batches of 512 * 100 rows per time, we can increase this number to process things a bit faster, however pyjet and matplotlib will always process everything at the same speed, so to process all the data will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn is the path to the file and fb is our file batch:\n",
    "fn = '/home/felipe/LHCOlympics_2020/data/events_anomalydetection.h5'\n",
    "fb = generator(fn,chunksize=512*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the tabular data I'm using pyjet to cluster the pseudojets and get the exclusive 4 jets, I'm also extracting the jet-substructure information with dcut =0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop is to get the $signal$ and $background$ events in the  resized_events_anomalydetection.h5 file, it can also be used in the full size file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for the calculation of deltaphi and deltaR elementwise in the subjets found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_delta_phi(phi1,phi2):\n",
    "    delta_phi = np.abs(phi1 - phi2)\n",
    "    if delta_phi > np.pi:\n",
    "            delta_phi = 2. * np.pi - delta_phi\n",
    "    return delta_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_R_sub(subjets, n_subjets):\n",
    "    lj = np.zeros([n_subjets], dtype=DTYPE_PTEPM)\n",
    "    if len(subjets) < n_subjets:\n",
    "        for i in range(len(subjets)):\n",
    "            lj[i]['pT'] = subjets[i].pt\n",
    "            lj[i]['eta'] = subjets[i].eta\n",
    "            lj[i]['phi'] = subjets[i].phi\n",
    "    else:\n",
    "        for i in range(n_subjets):\n",
    "            lj[i]['pT'] = subjets[i].pt\n",
    "            lj[i]['eta'] = subjets[i].eta\n",
    "            lj[i]['phi'] = subjets[i].phi\n",
    "        \n",
    "    comb = combinations(lj, 2)\n",
    "    deltaR = []\n",
    "    for i in comb:\n",
    "        deleta = i[0]['eta'] - i[1]['eta']\n",
    "        deltaphi = comp_delta_phi(i[0]['phi'], i[1]['phi'])\n",
    "        deltaR.append(np.sqrt((deleta)**2 + (deltaphi)**2))\n",
    "    return deltaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for batch in fb:\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "    events_combined = batch.T\n",
    "    df = pd.DataFrame(columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                               'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                               'deltaeta', 'deltaphi',\n",
    "                               'mEratio1', 'mEratio2',\n",
    "                               'm_jj', 'pt_asym',\n",
    "                               'deltaR_sj12', 'deltaR_sj13',\n",
    "                               'deltaR_sj14', 'deltaR_sj23', \n",
    "                               'deltaR_sj24', 'deltaR_sj34',\n",
    "                               'n_subjets', 'event_idx' ])\n",
    "\n",
    "    for i in tqdm(range(events_combined.keys()[0],events_combined.keys()[-1]+1), total=len(batch)):\n",
    "        issignal = events_combined[i][2100]\n",
    "        if issignal == 1: #check if the events are signal and only process if yes\n",
    "            pseudojets_input = np.zeros(len([x for x in events_combined[i][::3] if x > 0]), dtype=DTYPE_PTEPM)\n",
    "            for j in range(700): #700 due to the way the jets are padded\n",
    "                if (events_combined[i][j*3]>0):\n",
    "                    pseudojets_input[j]['pT'] = events_combined[i][j*3]\n",
    "                    pseudojets_input[j]['eta'] = events_combined[i][j*3+1]\n",
    "                    pseudojets_input[j]['phi'] = events_combined[i][j*3+2]\n",
    "                    pass\n",
    "\n",
    "            sequence = cluster(pseudojets_input, R=1.0, algo='antikt')\n",
    "            jets = sequence.inclusive_jets(500)\n",
    "            jets2 = sequence.exclusive_jets(4)\n",
    "\n",
    "            pt_j1 = jets[0].pt\n",
    "            m_j1 = np.abs(jets[0].mass)\n",
    "            eta_j1 = jets[0].eta\n",
    "            phi_j1 = jets[0].phi\n",
    "            E_j1 = jets[0].e\n",
    "\n",
    "            try:\n",
    "                pt_j2 = jets[1].pt\n",
    "                m_j2 = np.abs(jets[1].mass)\n",
    "                eta_j2 = jets[1].eta\n",
    "                phi_j2 = jets[1].phi\n",
    "                E_j2 = jets[1].e\n",
    "            except IndexError:\n",
    "                pt_j2 = 0.\n",
    "                m_j2 = 0.\n",
    "                eta_j2 = 0.\n",
    "                phi_j2 = 0.\n",
    "                E_j2 = 0.\n",
    "            \n",
    "            deltaeta = np.abs(eta_j1 - eta_j2)\n",
    "            deltaphi = comp_delta_phi(phi_j1,phi_j2)\n",
    "\n",
    "            mEratio1 = m_j1/E_j1\n",
    "            try:\n",
    "                mEratio2 = m_j2/E_j2\n",
    "            except ZeroDivisionError:\n",
    "                mEratio2 = 0.\n",
    "\n",
    "            m_jj = m_j1 + m_j2\n",
    "\n",
    "            pt_asym = (pt_j1 - pt_j2)/(pt_j1 + pt_j2)\n",
    "\n",
    "            cluster_sj1 = cluster(jets[0].constituents_array(), R=0.4,p=1)\n",
    "            sj1 = cluster_sj1.inclusive_jets(20)\n",
    "            n_subjets = len(sj1)\n",
    "\n",
    "            \n",
    "            deltaR_list = delta_R_sub(sj1,4)\n",
    "            deltaR_sj12 = deltaR_list[0]\n",
    "            deltaR_sj13 = deltaR_list[1]\n",
    "            deltaR_sj14 = deltaR_list[2]\n",
    "            deltaR_sj23 = deltaR_list[3]\n",
    "            deltaR_sj24 = deltaR_list[4]\n",
    "            deltaR_sj34 = deltaR_list[5]\n",
    "\n",
    "            #make the pandas entry\n",
    "            entry = pd.DataFrame([[pt_j1, m_j1, eta_j1, phi_j1, E_j1, \n",
    "                                   pt_j2, m_j2, eta_j2, phi_j2, E_j2,\n",
    "                                   deltaeta, deltaphi,\n",
    "                                   mEratio1, mEratio2,\n",
    "                                   m_jj, pt_asym,\n",
    "                                   deltaR_sj12, deltaR_sj13,\n",
    "                                   deltaR_sj14, deltaR_sj23, \n",
    "                                   deltaR_sj24, deltaR_sj34,\n",
    "                                   n_subjets, i]],\n",
    "                                 columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                                          'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                                          'deltaeta', 'deltaphi',\n",
    "                                          'mEratio1', 'mEratio2',\n",
    "                                          'm_jj', 'pt_asym',\n",
    "                                          'deltaR_sj12', 'deltaR_sj13',\n",
    "                                          'deltaR_sj14', 'deltaR_sj23', \n",
    "                                          'deltaR_sj24', 'deltaR_sj34',\n",
    "                                          'n_subjets', 'event_idx'])\n",
    "\n",
    "            #appending the entry (row) into the main dataframe\n",
    "            df = df.append(entry)\n",
    "        else:\n",
    "            continue\n",
    "    #end the loop and save the batch\n",
    "    df.to_csv('../csv_data/signal/signal_batch_{}.csv'.format(batch_idx), sep=',', index=False)\n",
    "    batch_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### because the generator is exausted after loop through it, we have to instanciate it again to process the BG data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = generator(fn,chunksize=512*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for batch in fb:\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "    events_combined = batch.T\n",
    "    df = pd.DataFrame(columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                               'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                               'deltaeta', 'deltaphi',\n",
    "                               'mEratio1', 'mEratio2',\n",
    "                               'm_jj', 'pt_asym',\n",
    "                               'deltaR_sj12', 'deltaR_sj13',\n",
    "                               'deltaR_sj14', 'deltaR_sj23', \n",
    "                               'deltaR_sj24', 'deltaR_sj34',\n",
    "                               'n_subjets', 'event_idx' ])\n",
    "\n",
    "    for i in tqdm(range(events_combined.keys()[0],events_combined.keys()[-1]+1), total=len(batch)):\n",
    "        issignal = events_combined[i][2100]\n",
    "        if issignal == 0: #check if the events are signal and only process if yes\n",
    "            pseudojets_input = np.zeros(len([x for x in events_combined[i][::3] if x > 0]), dtype=DTYPE_PTEPM)\n",
    "            for j in range(700): #700 due to the way the jets are padded\n",
    "                if (events_combined[i][j*3]>0):\n",
    "                    pseudojets_input[j]['pT'] = events_combined[i][j*3]\n",
    "                    pseudojets_input[j]['eta'] = events_combined[i][j*3+1]\n",
    "                    pseudojets_input[j]['phi'] = events_combined[i][j*3+2]\n",
    "                    pass\n",
    "\n",
    "            sequence = cluster(pseudojets_input, R=1.0, algo='antikt')\n",
    "            jets = sequence.inclusive_jets(500)\n",
    "            jets2 = sequence.exclusive_jets(4)\n",
    "\n",
    "            pt_j1 = jets[0].pt\n",
    "            m_j1 = np.abs(jets[0].mass)\n",
    "            eta_j1 = jets[0].eta\n",
    "            phi_j1 = jets[0].phi\n",
    "            E_j1 = jets[0].e\n",
    "\n",
    "            try:\n",
    "                pt_j2 = jets[1].pt\n",
    "                m_j2 = np.abs(jets[1].mass)\n",
    "                eta_j2 = jets[1].eta\n",
    "                phi_j2 = jets[1].phi\n",
    "                E_j2 = jets[1].e\n",
    "            except IndexError:\n",
    "                pt_j2 = 0.\n",
    "                m_j2 = 0.\n",
    "                eta_j2 = 0.\n",
    "                phi_j2 = 0.\n",
    "                E_j2 = 0.\n",
    "                \n",
    "\n",
    "            deltaeta = np.abs(eta_j1 - eta_j2)\n",
    "            deltaphi = comp_delta_phi(phi_j1,phi_j2)\n",
    "\n",
    "            mEratio1 = m_j1/E_j1\n",
    "            \n",
    "            try:\n",
    "                mEratio2 = m_j2/E_j2\n",
    "            except ZeroDivisionError:\n",
    "                mEratio2 = 0.\n",
    "                \n",
    "            \n",
    "            m_jj = m_j1 + m_j2\n",
    "\n",
    "            pt_asym = (pt_j1 - pt_j2)/(pt_j1 + pt_j2)\n",
    "\n",
    "            cluster_sj1 = cluster(jets[0].constituents_array(), R=0.4,p=1)\n",
    "            sj1 = cluster_sj1.inclusive_jets(20)\n",
    "            n_subjets = len(sj1)\n",
    "\n",
    "            \n",
    "            deltaR_list = delta_R_sub(sj1,4)\n",
    "            deltaR_sj12 = deltaR_list[0]\n",
    "            deltaR_sj13 = deltaR_list[1]\n",
    "            deltaR_sj14 = deltaR_list[2]\n",
    "            deltaR_sj23 = deltaR_list[3]\n",
    "            deltaR_sj24 = deltaR_list[4]\n",
    "            deltaR_sj34 = deltaR_list[5]\n",
    "\n",
    "            #make the pandas entry\n",
    "            entry = pd.DataFrame([[pt_j1, m_j1, eta_j1, phi_j1, E_j1, \n",
    "                                   pt_j2, m_j2, eta_j2, phi_j2, E_j2,\n",
    "                                   deltaeta, deltaphi,\n",
    "                                   mEratio1, mEratio2,\n",
    "                                   m_jj, pt_asym,\n",
    "                                   deltaR_sj12, deltaR_sj13,\n",
    "                                   deltaR_sj14, deltaR_sj23, \n",
    "                                   deltaR_sj24, deltaR_sj34,\n",
    "                                   n_subjets, i]],\n",
    "                                 columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                                          'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                                          'deltaeta', 'deltaphi',\n",
    "                                          'mEratio1', 'mEratio2',\n",
    "                                          'm_jj', 'pt_asym',\n",
    "                                          'deltaR_sj12', 'deltaR_sj13',\n",
    "                                          'deltaR_sj14', 'deltaR_sj23', \n",
    "                                          'deltaR_sj24', 'deltaR_sj34',\n",
    "                                          'n_subjets', 'event_idx'])\n",
    "\n",
    "            #appending the entry (row) into the main dataframe\n",
    "            df = df.append(entry)\n",
    "        else:\n",
    "            continue\n",
    "    #end the loop and save the batch\n",
    "    df.to_csv('../csv_data/background/background_batch_{}.csv'.format(batch_idx), sep=',', index=False)\n",
    "    batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0./0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create the same tabular data using the blackbox and pythia background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackbox data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/felipe/LHCOlympics_2020/data/events_LHCO2020_BlackBox1.h5'\n",
    "fb = generator(fn,chunksize=512*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for batch in fb:\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "    events_combined = batch.T\n",
    "    df = pd.DataFrame(columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                               'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                               'deltaeta', 'deltaphi',\n",
    "                               'mEratio1', 'mEratio2',\n",
    "                               'm_jj', 'pt_asym',\n",
    "                               'deltaR_sj12', 'deltaR_sj13',\n",
    "                               'deltaR_sj14', 'deltaR_sj23', \n",
    "                               'deltaR_sj24', 'deltaR_sj34',\n",
    "                               'n_subjets', 'event_idx' ])\n",
    "\n",
    "    for i in tqdm(range(events_combined.keys()[0],events_combined.keys()[-1]+1), total=len(batch)):\n",
    "        pseudojets_input = np.zeros(len([x for x in events_combined[i][::3] if x > 0]), dtype=DTYPE_PTEPM)\n",
    "        for j in range(700): #700 due to the way the jets are padded\n",
    "            if (events_combined[i][j*3]>0):\n",
    "                pseudojets_input[j]['pT'] = events_combined[i][j*3]\n",
    "                pseudojets_input[j]['eta'] = events_combined[i][j*3+1]\n",
    "                pseudojets_input[j]['phi'] = events_combined[i][j*3+2]\n",
    "                pass\n",
    "\n",
    "        sequence = cluster(pseudojets_input, R=1.0, algo='antikt')\n",
    "        jets = sequence.inclusive_jets(500)\n",
    "        jets2 = sequence.exclusive_jets(4)\n",
    "\n",
    "        pt_j1 = jets[0].pt\n",
    "        m_j1 = np.abs(jets[0].mass)\n",
    "        eta_j1 = jets[0].eta\n",
    "        phi_j1 = jets[0].phi\n",
    "        E_j1 = jets[0].e\n",
    "        try:\n",
    "            pt_j2 = jets[1].pt\n",
    "            m_j2 = np.abs(jets[1].mass)\n",
    "            eta_j2 = jets[1].eta\n",
    "            phi_j2 = jets[1].phi\n",
    "            E_j2 = jets[1].e\n",
    "        except IndexError:\n",
    "            pt_j2 = 0.\n",
    "            m_j2 = 0.\n",
    "            eta_j2 = 0.\n",
    "            phi_j2 = 0.\n",
    "            E_j2 = 0.\n",
    "\n",
    "\n",
    "        deltaeta = np.abs(eta_j1 - eta_j2)\n",
    "        deltaphi = comp_delta_phi(phi_j1,phi_j2)\n",
    "\n",
    "        mEratio1 = m_j1/E_j1\n",
    "\n",
    "        try:\n",
    "            mEratio2 = m_j2/E_j2\n",
    "        except ZeroDivisionError:\n",
    "            mEratio2 = 0.\n",
    "\n",
    "            \n",
    "        m_jj = m_j1 + m_j2\n",
    "\n",
    "        pt_asym = (pt_j1 - pt_j2)/(pt_j1 + pt_j2)\n",
    "\n",
    "        cluster_sj1 = cluster(jets[0].constituents_array(), R=0.4,p=1)\n",
    "        sj1 = cluster_sj1.inclusive_jets(20)\n",
    "        n_subjets = len(sj1)\n",
    "\n",
    "\n",
    "        deltaR_list = delta_R_sub(sj1,4)\n",
    "        deltaR_sj12 = deltaR_list[0]\n",
    "        deltaR_sj13 = deltaR_list[1]\n",
    "        deltaR_sj14 = deltaR_list[2]\n",
    "        deltaR_sj23 = deltaR_list[3]\n",
    "        deltaR_sj24 = deltaR_list[4]\n",
    "        deltaR_sj34 = deltaR_list[5]\n",
    "\n",
    "        #make the pandas entry\n",
    "        entry = pd.DataFrame([[pt_j1, m_j1, eta_j1, phi_j1, E_j1, \n",
    "                               pt_j2, m_j2, eta_j2, phi_j2, E_j2,\n",
    "                               deltaeta, deltaphi,\n",
    "                               mEratio1, mEratio2,\n",
    "                               m_jj, pt_asym,\n",
    "                               deltaR_sj12, deltaR_sj13,\n",
    "                               deltaR_sj14, deltaR_sj23, \n",
    "                               deltaR_sj24, deltaR_sj34,\n",
    "                               n_subjets, i]],\n",
    "                             columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                                      'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                                      'deltaeta', 'deltaphi',\n",
    "                                      'mEratio1', 'mEratio2',\n",
    "                                      'm_jj', 'pt_asym',\n",
    "                                      'deltaR_sj12', 'deltaR_sj13',\n",
    "                                      'deltaR_sj14', 'deltaR_sj23', \n",
    "                                      'deltaR_sj24', 'deltaR_sj34',\n",
    "                                      'n_subjets', 'event_idx'])\n",
    "\n",
    "        #appending the entry (row) into the main dataframe\n",
    "        df = df.append(entry)\n",
    "    #end the loop and save the batch\n",
    "    df.to_csv('../csv_data/blackbox/blackbox_batch_{}.csv'.format(batch_idx), sep=',', index=False)\n",
    "    batch_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Pythia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/felipe/LHCOlympics_2020/data/events_LHCO2020_backgroundMC_Pythia.h5'\n",
    "fb = generator(fn,chunksize=512*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for batch in fb:\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "    events_combined = batch.T\n",
    "    df = pd.DataFrame(columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                               'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                               'deltaeta', 'deltaphi',\n",
    "                               'mEratio1', 'mEratio2',\n",
    "                               'm_jj', 'pt_asym',\n",
    "                               'deltaR_sj12', 'deltaR_sj13',\n",
    "                               'deltaR_sj14', 'deltaR_sj23', \n",
    "                               'deltaR_sj24', 'deltaR_sj34',\n",
    "                               'n_subjets', 'event_idx' ])\n",
    "\n",
    "    for i in tqdm(range(events_combined.keys()[0],events_combined.keys()[-1]+1), total=len(batch)):\n",
    "        pseudojets_input = np.zeros(len([x for x in events_combined[i][::3] if x > 0]), dtype=DTYPE_PTEPM)\n",
    "        for j in range(700): #700 due to the way the jets are padded\n",
    "            if (events_combined[i][j*3]>0):\n",
    "                pseudojets_input[j]['pT'] = events_combined[i][j*3]\n",
    "                pseudojets_input[j]['eta'] = events_combined[i][j*3+1]\n",
    "                pseudojets_input[j]['phi'] = events_combined[i][j*3+2]\n",
    "                pass\n",
    "\n",
    "        sequence = cluster(pseudojets_input, R=1.0, algo='antikt')\n",
    "        jets = sequence.inclusive_jets(500)\n",
    "        jets2 = sequence.exclusive_jets(4)\n",
    "\n",
    "        pt_j1 = jets[0].pt\n",
    "        m_j1 = np.abs(jets[0].mass)\n",
    "        eta_j1 = jets[0].eta\n",
    "        phi_j1 = jets[0].phi\n",
    "        E_j1 = jets[0].e\n",
    "        \n",
    "        try:\n",
    "            pt_j2 = jets[1].pt\n",
    "            m_j2 = np.abs(jets[1].mass)\n",
    "            eta_j2 = jets[1].eta\n",
    "            phi_j2 = jets[1].phi\n",
    "            E_j2 = jets[1].e\n",
    "        except IndexError:\n",
    "            pt_j2 = 0.\n",
    "            m_j2 = 0.\n",
    "            eta_j2 = 0.\n",
    "            phi_j2 = 0.\n",
    "            E_j2 = 0.\n",
    "\n",
    "\n",
    "        deltaeta = np.abs(eta_j1 - eta_j2)\n",
    "        deltaphi = comp_delta_phi(phi_j1,phi_j2)\n",
    "\n",
    "        mEratio1 = m_j1/E_j1\n",
    "\n",
    "        try:\n",
    "            mEratio2 = m_j2/E_j2\n",
    "        except ZeroDivisionError:\n",
    "            mEratio2 = 0.\n",
    "\n",
    "        m_jj = m_j1 + m_j2\n",
    "\n",
    "        pt_asym = (pt_j1 - pt_j2)/(pt_j1 + pt_j2)\n",
    "\n",
    "        cluster_sj1 = cluster(jets[0].constituents_array(), R=0.4,p=1)\n",
    "        sj1 = cluster_sj1.inclusive_jets(20)\n",
    "        n_subjets = len(sj1)\n",
    "\n",
    "\n",
    "        deltaR_list = delta_R_sub(sj1,4)\n",
    "        deltaR_sj12 = deltaR_list[0]\n",
    "        deltaR_sj13 = deltaR_list[1]\n",
    "        deltaR_sj14 = deltaR_list[2]\n",
    "        deltaR_sj23 = deltaR_list[3]\n",
    "        deltaR_sj24 = deltaR_list[4]\n",
    "        deltaR_sj34 = deltaR_list[5]\n",
    "\n",
    "        #make the pandas entry\n",
    "        entry = pd.DataFrame([[pt_j1, m_j1, eta_j1, phi_j1, E_j1, \n",
    "                               pt_j2, m_j2, eta_j2, phi_j2, E_j2,\n",
    "                               deltaeta, deltaphi,\n",
    "                               mEratio1, mEratio2,\n",
    "                               m_jj, pt_asym,\n",
    "                               deltaR_sj12, deltaR_sj13,\n",
    "                               deltaR_sj14, deltaR_sj23, \n",
    "                               deltaR_sj24, deltaR_sj34,\n",
    "                               n_subjets, i]],\n",
    "                             columns=['pt_j1', 'm_j1', 'eta_j1', 'phi_j1', 'E_j1', \n",
    "                                      'pt_j2', 'm_j2', 'eta_j2', 'phi_j2', 'E_j2',\n",
    "                                      'deltaeta', 'deltaphi',\n",
    "                                      'mEratio1', 'mEratio2',\n",
    "                                      'm_jj', 'pt_asym',\n",
    "                                      'deltaR_sj12', 'deltaR_sj13',\n",
    "                                      'deltaR_sj14', 'deltaR_sj23', \n",
    "                                      'deltaR_sj24', 'deltaR_sj34',\n",
    "                                      'n_subjets', 'event_idx'])\n",
    "\n",
    "        #appending the entry (row) into the main dataframe\n",
    "        df = df.append(entry)\n",
    "\n",
    "    #end the loop and save the batch\n",
    "    df.to_csv('../csv_data/background_pythia/background_pythia_batch_{}.csv'.format(batch_idx), sep=',', index=False)\n",
    "    batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scikit-HEP",
   "language": "python",
   "name": "scikit-hep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
